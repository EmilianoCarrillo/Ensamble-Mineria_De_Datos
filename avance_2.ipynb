{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA para el análisis, visualización de datos, y entrenamiento de algoritmos de clasificación\n",
    "\n",
    "## Tabla de Contenidos\n",
    "1. Introducción\n",
    "2. Importación de Datos\n",
    "3. Preprocesar Datos\n",
    "4. PCA <br/>\n",
    "    4.1 Aplicación del PCA <br/>\n",
    "    4.2 Análisis de resultados <br/>\n",
    "    4.3 Visualización del PCA 2D <br/>\n",
    "5. Detección de Outliers\n",
    "6. Clasificación <br/>\n",
    "    6.1 Clasificar <br/>\n",
    "    6.2 Predicción y Análisis <br/>\n",
    "    \n",
    "    \n",
    "## 1. Introducción\n",
    "    \n",
    "PCA es un algoritmo de reducción de dimensionalidad no supervisado. En este ejemplo lo emplearemos para satisfacer 3 objetivos:\n",
    "\n",
    "**1. Hacer un análisis** <br/>\n",
    "    Analizaremos la cantidad de componentes principales que son necesarios para resumir nuestros datos de una manera que no haya tanta pérdida de información. Este objetivo se establece únicamente como fase de experimentación.\n",
    "    \n",
    "**2. Facilitar la visualización de nuestros datos** <br/>\n",
    "Ocuparemos 2 componentes principales para poder graficar nuestros datos multidimensionales en una gráfica de dispersión. Así podremos entender mejor nuestra data y podemos detectar posibles outliers.\n",
    "    \n",
    "**3. Como paso de preprocesamiento para la clasificación de elementos** <br/>\n",
    "Por último ocuparemos PCA para resumir nuestros datos y eficientizar el entrenamiento de nuestro clasificador sin perder efectividad de clasificación.\n",
    "        \n",
    "\n",
    "## 2. Importación de Datos\n",
    "El primer paso es importar los datos que ocuparemos para el análisis. El archivo de entrada debe ser un archivo de texto plano con el formato siguiente:\n",
    "```\n",
    "No. Elementos\n",
    "No. Atributos\n",
    "No. Clases\n",
    "atrib_0, atrib_1, ..., atrib_n, clase\n",
    "atrib_0, atrib_1, ..., atrib_n, clase\n",
    "... ... ...\n",
    "atrib_0, atrib_1, ..., atrib_n, clase\n",
    "```\n",
    "\n",
    "### Preprocesar archivo\n",
    "Primero preprocesamos el archivo para obtener los metadatos de No. de elementos, atributos y clases que éste contiene en el encabezado y así construir nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "\n",
    "nombre_archivo = \"data2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open( nombre_archivo + \".txt\", \"r\") as archivo:\n",
    "        nElem = int(archivo.readline())\n",
    "        nAtrib = int(archivo.readline())\n",
    "        nClases = int(archivo.readline())\n",
    "        \n",
    "        atributos = []\n",
    "        for i in range(0, nAtrib):\n",
    "            atributos.append(\"atrib_\" + str(i+1))\n",
    "        \n",
    "        atributos.append(\"clase\")\n",
    "        data = pd.read_csv(archivo, delimiter=',', header=None)\n",
    "        data.columns = atributos\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print( \"ERROR: El archivo \" + nombre_archivo + \" no fue encontrado\");\n",
    "finally:\n",
    "    archivo.close();\n",
    "\n",
    "dataset = data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos obtener un pequeño vistazo de cómo se ve nuestro dataset hasta ahora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fin = dataset.drop('clase', 1)\n",
    "y_fin = dataset['clase']\n",
    "nComponentes = \"Sin Componentes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atrib_1</th>\n",
       "      <th>atrib_2</th>\n",
       "      <th>atrib_3</th>\n",
       "      <th>atrib_4</th>\n",
       "      <th>atrib_5</th>\n",
       "      <th>atrib_6</th>\n",
       "      <th>atrib_7</th>\n",
       "      <th>atrib_8</th>\n",
       "      <th>atrib_9</th>\n",
       "      <th>atrib_10</th>\n",
       "      <th>...</th>\n",
       "      <th>atrib_377</th>\n",
       "      <th>atrib_378</th>\n",
       "      <th>atrib_379</th>\n",
       "      <th>atrib_380</th>\n",
       "      <th>atrib_381</th>\n",
       "      <th>atrib_382</th>\n",
       "      <th>atrib_383</th>\n",
       "      <th>atrib_384</th>\n",
       "      <th>atrib_385</th>\n",
       "      <th>clase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>21.803851</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>21.745726</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>21.687600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>21.629474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>21.571348</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 386 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   atrib_1  atrib_2  atrib_3  atrib_4  atrib_5  atrib_6  atrib_7  atrib_8  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0    -0.25    -0.25   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0    -0.25    -0.25   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0    -0.25    -0.25   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0    -0.25    -0.25   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0    -0.25    -0.25   \n",
       "\n",
       "   atrib_9  atrib_10  ...  atrib_377  atrib_378  atrib_379  atrib_380  \\\n",
       "0    -0.25     -0.25  ...   0.980381        0.0        0.0        0.0   \n",
       "1    -0.25     -0.25  ...   0.977008        0.0        0.0        0.0   \n",
       "2    -0.25     -0.25  ...   0.977008        0.0        0.0        0.0   \n",
       "3    -0.25     -0.25  ...   0.977008        0.0        0.0        0.0   \n",
       "4    -0.25     -0.25  ...   0.976833        0.0        0.0        0.0   \n",
       "\n",
       "   atrib_381  atrib_382  atrib_383  atrib_384  atrib_385  clase  \n",
       "0        0.0        0.0      -0.25      -0.25  21.803851      0  \n",
       "1        0.0        0.0      -0.25      -0.25  21.745726      0  \n",
       "2        0.0        0.0      -0.25      -0.25  21.687600      0  \n",
       "3        0.0        0.0      -0.25      -0.25  21.629474      0  \n",
       "4        0.0        0.0      -0.25      -0.25  21.571348      0  \n",
       "\n",
       "[5 rows x 386 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocesar datos\n",
    "Como PCA se soporta de la desviación estándar de los datos para calcular la nueva proyección de nuestros datos, una variable con una desviación estándar alta tendrá un peso mayor para el cálculo de la proyección que una variable con una desviación estándar baja. Si normalizamos los datos, todas las variables tendrán la misma desviación estándar, por lo tanto, el cálculo no estará cargado. \n",
    "\n",
    "Además, como no tenemos conocimiento del dominio del conjunto de datos de ejemplo, no sabemos si las unidades de medida de sus variables son distintas. Otra razón por la cual normalizar nuestros datos.\n",
    "\n",
    "PCA se considera como un algoritmo no supervisado, esto quiere decir que se apoya únicamente del set de datos sin las clases asignadas. Por esto, el primer paso de preprocesamiento será dividir nuestro set en dos: el set con los atributos y el set de las clases de asignación. Paso continuo sería estandarizar los datos sin la columna de las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atrib_1</th>\n",
       "      <th>atrib_2</th>\n",
       "      <th>atrib_3</th>\n",
       "      <th>atrib_4</th>\n",
       "      <th>atrib_5</th>\n",
       "      <th>atrib_6</th>\n",
       "      <th>atrib_7</th>\n",
       "      <th>atrib_8</th>\n",
       "      <th>atrib_9</th>\n",
       "      <th>atrib_10</th>\n",
       "      <th>...</th>\n",
       "      <th>atrib_376</th>\n",
       "      <th>atrib_377</th>\n",
       "      <th>atrib_378</th>\n",
       "      <th>atrib_379</th>\n",
       "      <th>atrib_380</th>\n",
       "      <th>atrib_381</th>\n",
       "      <th>atrib_382</th>\n",
       "      <th>atrib_383</th>\n",
       "      <th>atrib_384</th>\n",
       "      <th>atrib_385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.458699</td>\n",
       "      <td>-0.307113</td>\n",
       "      <td>-0.243608</td>\n",
       "      <td>-0.307003</td>\n",
       "      <td>-0.518008</td>\n",
       "      <td>-0.675602</td>\n",
       "      <td>-1.003106</td>\n",
       "      <td>-0.760053</td>\n",
       "      <td>-0.659573</td>\n",
       "      <td>-0.1849</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.346831</td>\n",
       "      <td>2.398449</td>\n",
       "      <td>-0.608699</td>\n",
       "      <td>-0.69581</td>\n",
       "      <td>-0.707798</td>\n",
       "      <td>-0.499451</td>\n",
       "      <td>-0.009384</td>\n",
       "      <td>-1.20185</td>\n",
       "      <td>-0.641154</td>\n",
       "      <td>-0.332086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.458699</td>\n",
       "      <td>-0.307113</td>\n",
       "      <td>-0.243608</td>\n",
       "      <td>-0.307003</td>\n",
       "      <td>-0.518008</td>\n",
       "      <td>-0.675602</td>\n",
       "      <td>-1.003106</td>\n",
       "      <td>-0.760053</td>\n",
       "      <td>-0.659573</td>\n",
       "      <td>-0.1849</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.346831</td>\n",
       "      <td>2.388748</td>\n",
       "      <td>-0.608699</td>\n",
       "      <td>-0.69581</td>\n",
       "      <td>-0.707798</td>\n",
       "      <td>-0.499451</td>\n",
       "      <td>-0.009384</td>\n",
       "      <td>-1.20185</td>\n",
       "      <td>-0.641154</td>\n",
       "      <td>-0.339097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.458699</td>\n",
       "      <td>-0.307113</td>\n",
       "      <td>-0.243608</td>\n",
       "      <td>-0.307003</td>\n",
       "      <td>-0.518008</td>\n",
       "      <td>-0.675602</td>\n",
       "      <td>-1.003106</td>\n",
       "      <td>-0.760053</td>\n",
       "      <td>-0.659573</td>\n",
       "      <td>-0.1849</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.346831</td>\n",
       "      <td>2.388748</td>\n",
       "      <td>-0.608699</td>\n",
       "      <td>-0.69581</td>\n",
       "      <td>-0.707798</td>\n",
       "      <td>-0.499451</td>\n",
       "      <td>-0.009384</td>\n",
       "      <td>-1.20185</td>\n",
       "      <td>-0.641154</td>\n",
       "      <td>-0.346107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.458699</td>\n",
       "      <td>-0.307113</td>\n",
       "      <td>-0.243608</td>\n",
       "      <td>-0.307003</td>\n",
       "      <td>-0.518008</td>\n",
       "      <td>-0.675602</td>\n",
       "      <td>-1.003106</td>\n",
       "      <td>-0.760053</td>\n",
       "      <td>-0.659573</td>\n",
       "      <td>-0.1849</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.346831</td>\n",
       "      <td>2.388748</td>\n",
       "      <td>-0.608699</td>\n",
       "      <td>-0.69581</td>\n",
       "      <td>-0.707798</td>\n",
       "      <td>-0.499451</td>\n",
       "      <td>-0.009384</td>\n",
       "      <td>-1.20185</td>\n",
       "      <td>-0.641154</td>\n",
       "      <td>-0.353118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.458699</td>\n",
       "      <td>-0.307113</td>\n",
       "      <td>-0.243608</td>\n",
       "      <td>-0.307003</td>\n",
       "      <td>-0.518008</td>\n",
       "      <td>-0.675602</td>\n",
       "      <td>-1.003106</td>\n",
       "      <td>-0.760053</td>\n",
       "      <td>-0.659573</td>\n",
       "      <td>-0.1849</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.346831</td>\n",
       "      <td>2.388245</td>\n",
       "      <td>-0.608699</td>\n",
       "      <td>-0.69581</td>\n",
       "      <td>-0.707798</td>\n",
       "      <td>-0.499451</td>\n",
       "      <td>-0.009384</td>\n",
       "      <td>-1.20185</td>\n",
       "      <td>-0.641154</td>\n",
       "      <td>-0.360128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    atrib_1   atrib_2   atrib_3   atrib_4   atrib_5   atrib_6   atrib_7  \\\n",
       "0 -0.458699 -0.307113 -0.243608 -0.307003 -0.518008 -0.675602 -1.003106   \n",
       "1 -0.458699 -0.307113 -0.243608 -0.307003 -0.518008 -0.675602 -1.003106   \n",
       "2 -0.458699 -0.307113 -0.243608 -0.307003 -0.518008 -0.675602 -1.003106   \n",
       "3 -0.458699 -0.307113 -0.243608 -0.307003 -0.518008 -0.675602 -1.003106   \n",
       "4 -0.458699 -0.307113 -0.243608 -0.307003 -0.518008 -0.675602 -1.003106   \n",
       "\n",
       "    atrib_8   atrib_9  atrib_10  ...  atrib_376  atrib_377  atrib_378  \\\n",
       "0 -0.760053 -0.659573   -0.1849  ...  -1.346831   2.398449  -0.608699   \n",
       "1 -0.760053 -0.659573   -0.1849  ...  -1.346831   2.388748  -0.608699   \n",
       "2 -0.760053 -0.659573   -0.1849  ...  -1.346831   2.388748  -0.608699   \n",
       "3 -0.760053 -0.659573   -0.1849  ...  -1.346831   2.388748  -0.608699   \n",
       "4 -0.760053 -0.659573   -0.1849  ...  -1.346831   2.388245  -0.608699   \n",
       "\n",
       "   atrib_379  atrib_380  atrib_381  atrib_382  atrib_383  atrib_384  atrib_385  \n",
       "0   -0.69581  -0.707798  -0.499451  -0.009384   -1.20185  -0.641154  -0.332086  \n",
       "1   -0.69581  -0.707798  -0.499451  -0.009384   -1.20185  -0.641154  -0.339097  \n",
       "2   -0.69581  -0.707798  -0.499451  -0.009384   -1.20185  -0.641154  -0.346107  \n",
       "3   -0.69581  -0.707798  -0.499451  -0.009384   -1.20185  -0.641154  -0.353118  \n",
       "4   -0.69581  -0.707798  -0.499451  -0.009384   -1.20185  -0.641154  -0.360128  \n",
       "\n",
       "[5 rows x 385 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dataset.drop('clase', 1)\n",
    "y = dataset['clase']\n",
    "\n",
    "x_estandarizada = StandardScaler().fit_transform(x)\n",
    "\n",
    "try:\n",
    "    atributos.remove('clase')\n",
    "except:\n",
    "    print('')\n",
    "    \n",
    "x_fin = pd.DataFrame(data = x_estandarizada, columns = atributos)\n",
    "x_fin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PCA\n",
    "\n",
    "### 4.1. Aplicar PCA\n",
    "A continuación aplicaremos el PCA con tantos componentes principales como especifique el usuario.\n",
    "Se calculan 2 por defecto para que a continuación podamos graficar nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "nComponentes = int(input())\n",
    "pca = PCA(n_components=nComponentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos = []\n",
    "for i in range(nComponentes):\n",
    "    atributos.append('PC'+ str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pca = pca.fit_transform(x_estandarizada)\n",
    "pca_dataframe = pd.DataFrame(data = x_pca, columns=atributos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez aplicado el PCA, podemos observar que las dimensiones se redujeron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>PC12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.460596</td>\n",
       "      <td>-3.339109</td>\n",
       "      <td>-4.563161</td>\n",
       "      <td>3.327759</td>\n",
       "      <td>-2.208121</td>\n",
       "      <td>6.064103</td>\n",
       "      <td>-4.216890</td>\n",
       "      <td>-2.282480</td>\n",
       "      <td>2.566458</td>\n",
       "      <td>-0.184194</td>\n",
       "      <td>2.545967</td>\n",
       "      <td>1.755358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.476073</td>\n",
       "      <td>-3.105652</td>\n",
       "      <td>-4.598310</td>\n",
       "      <td>3.396971</td>\n",
       "      <td>-2.553714</td>\n",
       "      <td>6.859681</td>\n",
       "      <td>-4.514791</td>\n",
       "      <td>-2.525036</td>\n",
       "      <td>2.475475</td>\n",
       "      <td>-0.264140</td>\n",
       "      <td>2.139360</td>\n",
       "      <td>1.485149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.461930</td>\n",
       "      <td>-3.080342</td>\n",
       "      <td>-4.655892</td>\n",
       "      <td>3.387952</td>\n",
       "      <td>-2.533418</td>\n",
       "      <td>7.027484</td>\n",
       "      <td>-4.408574</td>\n",
       "      <td>-2.720884</td>\n",
       "      <td>2.408274</td>\n",
       "      <td>-0.350027</td>\n",
       "      <td>2.177446</td>\n",
       "      <td>1.629837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.266744</td>\n",
       "      <td>-3.118854</td>\n",
       "      <td>-4.481004</td>\n",
       "      <td>3.101231</td>\n",
       "      <td>-2.716013</td>\n",
       "      <td>6.562618</td>\n",
       "      <td>-3.877002</td>\n",
       "      <td>-2.767032</td>\n",
       "      <td>2.268119</td>\n",
       "      <td>-0.407711</td>\n",
       "      <td>2.667307</td>\n",
       "      <td>2.427876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.291467</td>\n",
       "      <td>-3.159250</td>\n",
       "      <td>-4.525222</td>\n",
       "      <td>3.179001</td>\n",
       "      <td>-2.780219</td>\n",
       "      <td>6.549292</td>\n",
       "      <td>-3.847466</td>\n",
       "      <td>-2.891800</td>\n",
       "      <td>2.291335</td>\n",
       "      <td>-0.392369</td>\n",
       "      <td>2.794697</td>\n",
       "      <td>2.533093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0  10.460596 -3.339109 -4.563161  3.327759 -2.208121  6.064103 -4.216890   \n",
       "1  10.476073 -3.105652 -4.598310  3.396971 -2.553714  6.859681 -4.514791   \n",
       "2  10.461930 -3.080342 -4.655892  3.387952 -2.533418  7.027484 -4.408574   \n",
       "3  10.266744 -3.118854 -4.481004  3.101231 -2.716013  6.562618 -3.877002   \n",
       "4  10.291467 -3.159250 -4.525222  3.179001 -2.780219  6.549292 -3.847466   \n",
       "\n",
       "        PC8       PC9      PC10      PC11      PC12  \n",
       "0 -2.282480  2.566458 -0.184194  2.545967  1.755358  \n",
       "1 -2.525036  2.475475 -0.264140  2.139360  1.485149  \n",
       "2 -2.720884  2.408274 -0.350027  2.177446  1.629837  \n",
       "3 -2.767032  2.268119 -0.407711  2.667307  2.427876  \n",
       "4 -2.891800  2.291335 -0.392369  2.794697  2.533093  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_fin = pca_dataframe\n",
    "x_fin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Clasificación\n",
    "Tener una gran cantidad de atributos en un dataset afecta el rendimiento y la precisión de los algoritmos de clasificación. Nuestro dataset original contenía 19 atributos, los cuales, a través de la técnica de reducción de dimensionalidad de PCA, logramos reducir a 2.\n",
    "\n",
    "En este ejemplo entrenaremos un árbol de decisión con nuestros datos reducidos con PCA. En seguida, analizaremos la precisión de éste cuando es entrenado con distintas cantidades de Componentes Principales. El objetivo es ver el número óptimo de Componentes Principales que nos permitan reducir el tiempo de entrenamiento del clasificador al resumir nuestros datos adecuadamente, y conservar un elevado porcentaje de precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.concat([x_fin, y_fin], axis = 1);\n",
    "\n",
    "X = dataframe.drop('clase', 1)\n",
    "y = dataframe['clase']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método de clasificación por árbol de decisión es un método de aprendizaje supervisado, por esto, debemos entrenarlo con el set de atributos y su clasificación inicial. Además, para probar la precisión de éste, necesitamos un set de prueba. Por ello procederemos a partir nuestro set de datos en 2 secciones: Un set para entrenar a nuestro clasificador, y uno para entrenarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avance 2\n",
    "Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* CLASIFICADOR KNN *******\n",
      "\n",
      "Matriz de confusión: \n",
      "[[11  1  0  0  0  0]\n",
      " [ 0 40  0  0  0  1]\n",
      " [ 0  1  9  0  2  0]\n",
      " [ 0  0  0  4  0  0]\n",
      " [ 0  0  0  0  6  2]\n",
      " [ 0  0  0  0  0 20]]\n",
      "\n",
      "Reporte de clasificación: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        12\n",
      "           1       0.95      0.98      0.96        41\n",
      "           2       1.00      0.75      0.86        12\n",
      "           3       1.00      1.00      1.00         4\n",
      "           4       0.75      0.75      0.75         8\n",
      "           5       0.87      1.00      0.93        20\n",
      "\n",
      "    accuracy                           0.93        97\n",
      "   macro avg       0.93      0.90      0.91        97\n",
      "weighted avg       0.93      0.93      0.93        97\n",
      "\n",
      "\n",
      "Puntaje de precisión: \n",
      "0.9278350515463918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(\"******* CLASIFICADOR KNN *******\\n\")\n",
    "print(\"Matriz de confusión: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nReporte de clasificación: \")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nPuntaje de precisión: \")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "\n",
    "# Calcular error para valores K entre 1 y 40\n",
    "for i in range(1, 40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Promedio')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Frecuencia de error por Valores K')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Promedio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.959 (+/-0.019) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.974 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.966 (+/-0.019) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.977 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.964 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.977 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.961 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.974 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.966 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.977 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.966 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.974 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.953 (+/-0.055) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.979 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.961 (+/-0.025) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.979 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.961 (+/-0.033) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.972 (+/-0.019) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.966 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.974 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.969 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.972 (+/-0.019) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.966 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.972 (+/-0.019) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.964 (+/-0.019) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.974 (+/-0.015) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.964 (+/-0.032) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.979 (+/-0.015) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.969 (+/-0.013) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.979 (+/-0.015) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.964 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.974 (+/-0.015) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.966 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.974 (+/-0.015) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.964 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.977 (+/-0.013) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.972 (+/-0.019) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.977 (+/-0.013) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.948 (+/-0.026) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.979 (+/-0.015) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.969 (+/-0.025) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.977 (+/-0.013) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.969 (+/-0.025) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.974 (+/-0.015) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.964 (+/-0.007) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.977 (+/-0.000) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.959 (+/-0.029) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.969 (+/-0.013) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(max_iter=300)\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Best paramete set\n",
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "\n",
    "# All results\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test , clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* CLASIFICADOR NEURAL NET*******\n",
      "\n",
      "Matriz de confusión: \n",
      "[[11  1  0  0  0  0]\n",
      " [ 0 41  0  0  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0  4  0  0]\n",
      " [ 0  0  0  0  8  0]\n",
      " [ 0  0  0  0  0 20]]\n",
      "\n",
      "Reporte de clasificación: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        12\n",
      "           1       0.98      1.00      0.99        41\n",
      "           2       1.00      1.00      1.00        12\n",
      "           3       1.00      1.00      1.00         4\n",
      "           4       1.00      1.00      1.00         8\n",
      "           5       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           0.99        97\n",
      "   macro avg       1.00      0.99      0.99        97\n",
      "weighted avg       0.99      0.99      0.99        97\n",
      "\n",
      "\n",
      "Puntaje de precisión: \n",
      "0.9896907216494846\n"
     ]
    }
   ],
   "source": [
    "print(\"******* CLASIFICADOR NEURAL NET*******\\n\")\n",
    "print(\"Matriz de confusión: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nReporte de clasificación: \")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nPuntaje de precisión: \")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB().fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* CLASIFICADOR NAIVE BAYES *******\n",
      "\n",
      "Matriz de confusión: \n",
      "[[ 9  1  0  0  0  2]\n",
      " [ 1 39  0  0  0  1]\n",
      " [ 2  2  8  0  0  0]\n",
      " [ 0  0  0  4  0  0]\n",
      " [ 0  1  0  0  5  2]\n",
      " [ 0  1  0  0  0 19]]\n",
      "\n",
      "Reporte de clasificación: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75        12\n",
      "           1       0.89      0.95      0.92        41\n",
      "           2       1.00      0.67      0.80        12\n",
      "           3       1.00      1.00      1.00         4\n",
      "           4       1.00      0.62      0.77         8\n",
      "           5       0.79      0.95      0.86        20\n",
      "\n",
      "    accuracy                           0.87        97\n",
      "   macro avg       0.90      0.82      0.85        97\n",
      "weighted avg       0.88      0.87      0.86        97\n",
      "\n",
      "\n",
      "Puntaje de precisión: \n",
      "0.865979381443299\n"
     ]
    }
   ],
   "source": [
    "print(\"******* CLASIFICADOR NAIVE BAYES *******\\n\")\n",
    "print(\"Matriz de confusión: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nReporte de clasificación: \")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nPuntaje de precisión: \")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
